{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b4daaa-6ff8-467c-8a9b-c56d3e4d9f8b",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = https://project.lsst.org/sites/default/files/Rubin-O-Logo_0.png width=250 style=\"padding: 10px\" alt=\"Vera C. Rubin Observatory Logo\"> \n",
    "<h1 style=\"margin-top: 10px\">Retrieve and Aggregate Zooniverse Output</h1>\n",
    "Authors: Becky Nevin, Clare Higgs, and Eric Rosas <br>\n",
    "Contact author: Clare Higgs <br>\n",
    "Last verified to run: 2024-10-07 <br>\n",
    "LSST Science Pipelines version: Weekly 2024_37 <br>\n",
    "Container size: small or medium <br>\n",
    "Targeted learning level: intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16d57a-9af8-4fc9-bf86-8724024516e6",
   "metadata": {},
   "source": [
    "<b>Description:</b> This notebook guides a PI through the process of retrieving classification data from Zooniverse and builds upon Hayley Robert's Aggregation notebook example. <br><br>\n",
    "<b>Skills:</b> \n",
    "<br><br>\n",
    "<b>LSST Data Products:</b> n/a<br><br>\n",
    "<b>Packages:</b> rubin.citsci, utils (citsci plotting and display utilities),  <br><br>\n",
    "<b>Credit:</b> Hayley Roberts' aggregation code https://github.com/astrohayley/SLSN-Aggregation-Example/blob/main/SLSN_batch_aggregation.py<br><br>\n",
    "<b>Get Support: </b>PIs new to DP0 are encouraged to find documentation and resources at <a href=\"https://dp0-2.lsst.io/\">dp0-2.lsst.io</a>. Support for this notebook is available and questions are welcome at cscience@lsst.org."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa844a-2bd3-41e4-9058-f5ce85c3fc54",
   "metadata": {},
   "source": [
    "## 1. Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "This notebook provides an introduction to how to use the Zooniverse panoptes client and rubin.citsci package to retrieve classifications from Zooniverse and aggregate the results. Data aggregation in this context is collecting classifications across all citizen scientists and summarizing them by subject in terms of classifier majority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3b241-4e92-49cd-9148-c6b180dc11d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T17:44:28.705146Z",
     "iopub.status.busy": "2024-06-20T17:44:28.704785Z",
     "iopub.status.idle": "2024-06-20T17:44:28.708543Z",
     "shell.execute_reply": "2024-06-20T17:44:28.707909Z",
     "shell.execute_reply.started": "2024-06-20T17:44:28.705123Z"
    }
   },
   "source": [
    "### 1.1 Package imports <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cdc872-8bdf-485b-921f-bb9bd5b597dd",
   "metadata": {},
   "source": [
    "#### Install Pipeline Package\n",
    "\n",
    "First, install the Rubin Citizen Science Pipeline package by doing the following:\n",
    "\n",
    "1. Open up a New Launcher tab\n",
    "2. In the \"Other\" section of the New Launcher tab, click \"Terminal\"\n",
    "3. Use `pip` to install the `rubin.citsci` package by entering the following command:\n",
    "```\n",
    "pip install rubin.citsci\n",
    "```\n",
    "Note that this package will soon be installed directly on RSP.\n",
    "\n",
    "If this package is already installed, make sure it is updated:\n",
    "```\n",
    "pip install --u rubin.citsci\n",
    "```\n",
    "\n",
    "4. Confirm the next cell containing `from rubin.citsci import pipeline` works as expected and does not throw an error\n",
    "\n",
    "5. Install panoptes_client:\n",
    "```\n",
    "pip install panoptes_client\n",
    "pip install panoptes_aggregation\n",
    "```\n",
    "\n",
    "6. If the pip install doesn't work for `panoptes_aggregation`:\n",
    "```\n",
    "pip install -U git+git://github.com/zooniverse/aggregation-for-caesar.git\n",
    "```\n",
    "(https://www.zooniverse.org/talk/1322/2415041?comment=3969837&page=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d65d903-8012-43e3-ab19-d94b3f422e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:35:03.323829Z",
     "iopub.status.busy": "2024-10-07T17:35:03.323647Z",
     "iopub.status.idle": "2024-10-07T17:35:05.399573Z",
     "shell.execute_reply": "2024-10-07T17:35:05.398928Z",
     "shell.execute_reply.started": "2024-10-07T17:35:03.323811Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Zooniverse tools\n",
    "from panoptes_client import Panoptes, Workflow\n",
    "from panoptes_aggregation.extractors.utilities import annotation_by_task\n",
    "from panoptes_aggregation.extractors import question_extractor\n",
    "from panoptes_aggregation.reducers import question_consensus_reducer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rubin.citsci import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65e56b-028b-425f-b3c3-87233734a9d7",
   "metadata": {},
   "source": [
    "### 1.2 Define functions and parameters <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "Credit for these functions goes to Hayley Roberts at Zooniverse. This includes:\n",
    "- `download_classifications`: A function to download the classifications given a workflow ID in, which returns a dataframe\n",
    "- `extract_data`: A function to extract user annotations by task and sort by when they were classified??? This can be modified for other classification tasks such as drawing, please see the Zooniverse documentation.\n",
    "- `aggregate_data`: A function that groups by task and user, selects the most recent classification from each user, and uses the Zooniverse `question_consesus_reducer` function to determine the consensus for each subject ID amongst all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d951495-9ed7-44ed-bffe-04504679e8bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:56:51.944909Z",
     "iopub.status.busy": "2024-10-07T17:56:51.944542Z",
     "iopub.status.idle": "2024-10-07T17:56:51.957537Z",
     "shell.execute_reply": "2024-10-07T17:56:51.956816Z",
     "shell.execute_reply.started": "2024-10-07T17:56:51.944885Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_classifications(WORKFLOW_ID, client):\n",
    "    \"\"\"\n",
    "    Downloads data from Zooniverse\n",
    "\n",
    "    Args:\n",
    "        WORKFLOW_ID (int): Workflow ID of workflow being aggregated\n",
    "        client: Logged in Zooniverse client\n",
    "\n",
    "    Returns:\n",
    "        classification_data (DataFrame): Raw classifications from Zooniverse\n",
    "    \"\"\"\n",
    "    print('beginning function')\n",
    "    workflow = Workflow(WORKFLOW_ID)\n",
    "    # generate the classifications \n",
    "    # if generate=True, it generates a new classification report,\n",
    "    # which can take a long time because they’re queued in the Zooniverse system.\n",
    "    # It’s the same as going to the project builder and clicking the “request new report”.\n",
    "    # If you don't care about new classifications and are okay with downloading\n",
    "    # an older report that you already generated, you can set this flag to False\n",
    "    with client:\n",
    "        classification_export = workflow.get_export('classifications',\n",
    "                                                    generate=False,\n",
    "                                                    wait=False)\n",
    "        # since it's a partial class, call it to get the DictReader object\n",
    "        csv_dictreader_instance = classification_export.csv_dictreader()\n",
    "        classification_rows = [row for row in tqdm(csv_dictreader_instance, file=sys.stdout)]\n",
    "    # convert to pandas dataframe\n",
    "    classification_data = pd.DataFrame.from_dict(classification_rows)\n",
    "    return classification_data\n",
    "\n",
    "\n",
    "\n",
    "def extract_data(classification_data):\n",
    "    \"\"\"\n",
    "    Extracts annotations from the classification data\n",
    "\n",
    "    Args:\n",
    "        classification_data (DataFrame): Raw classifications from Zooniverse\n",
    "\n",
    "    Returns:\n",
    "        extracted_data (DataFrame): Extracted annotations from raw classification data\n",
    "    \"\"\"\n",
    "    # set up our list where we will store the extracted data temporarily\n",
    "    extracted_rows = []\n",
    "\n",
    "    # iterate through our classification data\n",
    "    for i in range(len(classification_data)):\n",
    "\n",
    "        # access the specific row and extract the annotations\n",
    "        row = classification_data.iloc[i]\n",
    "        for annotation in json.loads(row.annotations):\n",
    "            row_annotation = annotation_by_task({'annotations': [annotation]})\n",
    "            extract = question_extractor(row_annotation)\n",
    "            print('row.subject_data', row.subject_data)\n",
    "            print('str of the subject_id', str(row.subject_ids))\n",
    "            objectId = row.subject_data[str(row.subject_ids)][\"objectId\"]\n",
    "            print('objectId', objectId)\n",
    "\n",
    "\n",
    "            print('row.subject_data', row.subject_data)\n",
    "            print('str of the subject_id', str(row.subject_ids))\n",
    "            \n",
    "            subject_id_str = str(row.subject_ids)\n",
    "            \n",
    "            # Check if the subject ID exists and is a dictionary\n",
    "            if subject_id_str in row.subject_data and isinstance(row.subject_data[subject_id_str], dict):\n",
    "                objectId = row.subject_data[subject_id_str][\"objectId\"]\n",
    "                print('objectId', objectId)\n",
    "            else:\n",
    "                print(f\"Key '{subject_id_str}' not found in subject_data or it is not a dictionary.\")\n",
    "\n",
    "            \n",
    "            STOP\n",
    "            # add the extracted annotations to our temporary list along with some other additional data\n",
    "            extracted_rows.append({\n",
    "                'classification_id': row.classification_id,\n",
    "                'subject_id':        row.subject_ids,\n",
    "                'user_name':         row.user_name,\n",
    "                'user_id':           row.user_id,\n",
    "                'created_at':        row.created_at,\n",
    "                'metadata':          row.subject_data,\n",
    "                'data':              json.dumps(extract),\n",
    "                'task':              annotation['task']\n",
    "            })\n",
    "\n",
    "\n",
    "    # convert the extracted data to a pandas dataframe and sort\n",
    "    extracted_data = pd.DataFrame.from_dict(extracted_rows)\n",
    "    extracted_data.sort_values(['subject_id', 'created_at'], inplace=True)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "def last_filter(data):\n",
    "    \"\"\"\n",
    "    Determines the most recently submitted classifications\n",
    "    \"\"\"\n",
    "    last_time = data.created_at.max()\n",
    "    ldx = data.created_at == last_time\n",
    "    return data[ldx]\n",
    "\n",
    "def aggregate_data(extracted_data):\n",
    "    \"\"\"\n",
    "    Aggregates question data from extracted annotations\n",
    "\n",
    "    Args:\n",
    "        extracted_data (DataFrame): Extracted annotations from raw classifications\n",
    "\n",
    "    Returns:\n",
    "        aggregated_data (DataFrame): Aggregated data for the given workflow\n",
    "    \"\"\"\n",
    "    # generate an array of unique subject ids - these are the ones that we will iterate over\n",
    "    subject_ids_unique = np.unique(extracted_data.subject_id)\n",
    "\n",
    "    # Create a dictionary to map subject IDs to their corresponding metadata\n",
    "    metadata = extracted_data.groupby('subject_id')['metadata'].unique()\n",
    "\n",
    "    print('len subject-ids-unique', len(subject_ids_unique))\n",
    "    print('metadata saved', len(metadata))\n",
    "    print(metadata)\n",
    "    STOP\n",
    "    \n",
    "\n",
    "    # set up a temporary list to store reduced data\n",
    "    aggregated_rows = []\n",
    "\n",
    "    # determine the total number of tasks\n",
    "    tasks = np.unique(extracted_data.task)\n",
    "\n",
    "    # iterating over each unique subject id\n",
    "    for i in range(len(subject_ids_unique)):\n",
    "\n",
    "        # determine the subject_id to work on\n",
    "        subject_id = subject_ids_unique[i]\n",
    "\n",
    "        # filter the extract_data dataframe for only the subject_id that is being worked on\n",
    "        extract_data_subject = extracted_data[extracted_data.subject_id==subject_id].drop_duplicates()\n",
    "\n",
    "        for task in tasks:\n",
    "\n",
    "            extract_data_filtered = extract_data_subject[extract_data_subject.task == task]\n",
    "\n",
    "            # if there are less unique user submissions than classifications, filter for the most recently updated classification\n",
    "            if (len(extract_data_filtered.user_name.unique()) < len(extract_data_filtered)):\n",
    "                extract_data_filtered = extract_data_filtered.groupby(['user_name'], group_keys=False).apply(last_filter)\n",
    "\n",
    "            # iterate through the filtered extract data to prepare for the reducer\n",
    "            classifications_to_reduce = [json.loads(extract_data_filtered.iloc[j].data) for j in range(len(extract_data_filtered))]\n",
    "\n",
    "            # use the Zooniverse question_consesus_reducer to get the final consensus\n",
    "            # WHAT ARE THE ARGUMENTS THAT ARE OPTIONAL HERE?\n",
    "            reduction = question_consensus_reducer(classifications_to_reduce)\n",
    "\n",
    "            # add the subject id to our reduction data\n",
    "            reduction['subject_id'] = subject_id\n",
    "            reduction['task'] = task\n",
    "\n",
    "            # add the data to our temporary list\n",
    "            aggregated_rows.append(reduction)\n",
    "\n",
    "\n",
    "    # converting the result to a dataframe\n",
    "    aggregated_data = pd.DataFrame.from_dict(aggregated_rows)\n",
    "\n",
    "    # drop rows that are nan\n",
    "    aggregated_data.dropna(inplace=True)\n",
    "\n",
    "    return aggregated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a708c0-046f-4634-a22f-a80dd9b613f2",
   "metadata": {},
   "source": [
    "## 2. Log into Zooniverse and find the workflow to download classifications from\n",
    "If you're running this notebook, you should already have a Zooniverse account with a project with classifications. If you do not yet have an account, please return to notebook `01_Introduction_to_Citsci_Pipeline.ipynb`.\n",
    "\n",
    "IMPORTANT: Your Zooniverse project must be set to \"public\", a \"private\" project will not work. Select this setting under the \"Visibility\" tab, (it does not need to be set to live). \n",
    "\n",
    "Supply the email associated with your Zooniverse account, and then follow the instructions in the prompt to log in and select your project by slug name. \n",
    "\n",
    "A \"slug\" is the string of your Zooniverse username and your project name without the leading forward slash, for instance: \"username/project-name\". [Click here for more details](https://www.zooniverse.org/talk/18/967061?comment=1898157&page=1).\n",
    "\n",
    "**The `rubin.citsci` package includes a method that creates a Zooniverse project from template. If you wish to use this feature, do not provide a slug_name and run the subsequent cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7be9aa4e-4ac6-473c-9660-29afbfa9dc74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:50:25.026082Z",
     "iopub.status.busy": "2024-10-07T17:50:25.025343Z",
     "iopub.status.idle": "2024-10-07T17:50:29.070666Z",
     "shell.execute_reply": "2024-10-07T17:50:29.069801Z",
     "shell.execute_reply.started": "2024-10-07T17:50:25.026055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and running utilities to establish a link with Zooniverse\n",
      "Enter your Zooniverse username followed by password below\n",
      "Enter your Zooniverse credentials...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m email \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeckynevin@gmail.com\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m cit_sci_pipeline \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mCitSciPipeline()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcit_sci_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin_to_zooniverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43memail\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rubin/citsci/pipeline.py:106\u001b[0m, in \u001b[0;36mCitSciPipeline.login_to_zooniverse\u001b[0;34m(self, email)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your Zooniverse username followed by password below\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memail \u001b[38;5;241m=\u001b[39m email\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mpanoptes_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPanoptes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteractive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mlogged_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou now are logged in to the Zooniverse platform.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/panoptes_client/panoptes.py:112\u001b[0m, in \u001b[0;36mPanoptes.connect\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    connect(username=None, password=None, endpoint=None, admin=False)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m        Panoptes.connect(endpoint='https://panoptes.example.com')\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_local\u001b[38;5;241m.\u001b[39mpanoptes_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_local\u001b[38;5;241m.\u001b[39mpanoptes_client\u001b[38;5;241m.\u001b[39mlogin()\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_local\u001b[38;5;241m.\u001b[39mpanoptes_client\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/panoptes_client/panoptes.py:143\u001b[0m, in \u001b[0;36mPanoptes.__init__\u001b[0;34m(self, endpoint, client_id, client_secret, redirect_url, username, password, login, admin)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musername \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassword \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musername\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogin()\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mredirect_url \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    147\u001b[0m     redirect_url \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPANOPTES_REDIRECT_URL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/panoptes_client/panoptes.py:456\u001b[0m, in \u001b[0;36mPanoptes._auth\u001b[0;34m(self, auth_type, username, password)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m username \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m password \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteractive\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 456\u001b[0m         username, password \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteractive_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m auth_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyring\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;66;03m# Get credentials from python keyring\u001b[39;00m\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/panoptes_client/panoptes.py:512\u001b[0m, in \u001b[0;36mPanoptes.interactive_login\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minteractive_login\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter your Zooniverse credentials...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 512\u001b[0m     username \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUsername: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m     password \u001b[38;5;241m=\u001b[39m getpass\u001b[38;5;241m.\u001b[39mgetpass()\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m username, password\n",
      "File \u001b[0;32m/opt/lsst/software/stack/conda/envs/lsst-scipipe-9.0.0/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/lsst/software/stack/conda/envs/lsst-scipipe-9.0.0/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "email = \"beckynevin@gmail.com\"\n",
    "cit_sci_pipeline = pipeline.CitSciPipeline()\n",
    "cit_sci_pipeline.login_to_zooniverse(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3426882-9f5c-4f8e-bdfb-1daed5230721",
   "metadata": {},
   "source": [
    "Use the `list_workflows` method to find the workflow ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f5808b1-109f-4417-8dd5-003d7d6f83f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:50:32.293681Z",
     "iopub.status.busy": "2024-10-07T17:50:32.292783Z",
     "iopub.status.idle": "2024-10-07T17:50:32.297409Z",
     "shell.execute_reply": "2024-10-07T17:50:32.296643Z",
     "shell.execute_reply.started": "2024-10-07T17:50:32.293653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please log in first using login_to_zooniverse() first before attempting to retrieve workflows.\n"
     ]
    }
   ],
   "source": [
    "cit_sci_pipeline.list_workflows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2d1d1-de4d-414b-afb9-e5b3f6957b68",
   "metadata": {},
   "source": [
    "Copy and paste the above ID into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "505d46f9-c80f-421c-b8d8-92e3093b4d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:35:20.565709Z",
     "iopub.status.busy": "2024-10-07T17:35:20.565392Z",
     "iopub.status.idle": "2024-10-07T17:35:20.569071Z",
     "shell.execute_reply": "2024-10-07T17:35:20.568404Z",
     "shell.execute_reply.started": "2024-10-07T17:35:20.565686Z"
    }
   },
   "outputs": [],
   "source": [
    "WORKFLOW_ID = 27509"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ff23f-b321-4277-a28e-6a2f33e28b1a",
   "metadata": {},
   "source": [
    "## 3. Download the classifications\n",
    "These will still be in the raw format. This function reads from the output csv and puts all rows into a dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8e0291a-d5e7-4fca-88d0-6930d32f2d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:50:43.986125Z",
     "iopub.status.busy": "2024-10-07T17:50:43.985164Z",
     "iopub.status.idle": "2024-10-07T17:50:44.094955Z",
     "shell.execute_reply": "2024-10-07T17:50:44.094214Z",
     "shell.execute_reply.started": "2024-10-07T17:50:43.986097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning function\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object does not support the context manager protocol",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m cit_sci_pipeline\u001b[38;5;241m.\u001b[39mclient\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# how long should this take?\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m classification_data \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_classifications\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWORKFLOW_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 20\u001b[0m, in \u001b[0;36mdownload_classifications\u001b[0;34m(WORKFLOW_ID, client)\u001b[0m\n\u001b[1;32m     13\u001b[0m workflow \u001b[38;5;241m=\u001b[39m Workflow(WORKFLOW_ID)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# generate the classifications \u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# if generate=True, it generates a new classification report,\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# which can take a long time because they’re queued in the Zooniverse system.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# It’s the same as going to the project builder and clicking the “request new report”.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# If you don't care about new classifications and are okay with downloading\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# an older report that you already generated, you can set this flag to False\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassification_export\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_export\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassifications\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mgenerate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# since it's a partial class, call it to get the DictReader object\u001b[39;49;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object does not support the context manager protocol"
     ]
    }
   ],
   "source": [
    "client = cit_sci_pipeline.client\n",
    "# how long should this take?\n",
    "classification_data = download_classifications(WORKFLOW_ID, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87efe634-b609-483f-b3d3-49f7623fc565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:50:50.865870Z",
     "iopub.status.busy": "2024-10-07T17:50:50.865443Z",
     "iopub.status.idle": "2024-10-07T17:50:50.886378Z",
     "shell.execute_reply": "2024-10-07T17:50:50.885600Z",
     "shell.execute_reply.started": "2024-10-07T17:50:50.865836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>workflow_id</th>\n",
       "      <th>workflow_name</th>\n",
       "      <th>workflow_version</th>\n",
       "      <th>created_at</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>expert</th>\n",
       "      <th>metadata</th>\n",
       "      <th>annotations</th>\n",
       "      <th>subject_data</th>\n",
       "      <th>subject_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589019044</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024-10-07 16:08:01 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247085\":{\"retired\":null,\"objectId\":\"16514...</td>\n",
       "      <td>103247085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589019067</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024-10-07 16:08:07 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247082\":{\"retired\":null,\"objectId\":\"15679...</td>\n",
       "      <td>103247082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589019090</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024-10-07 16:08:12 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247086\":{\"retired\":null,\"objectId\":\"16515...</td>\n",
       "      <td>103247086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>589019097</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024-10-07 16:08:14 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247083\":{\"retired\":null,\"objectId\":\"16509...</td>\n",
       "      <td>103247083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589019337</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:09:17 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247087\":{\"retired\":null,\"objectId\":\"16513...</td>\n",
       "      <td>103247087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>589020345</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:13 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247082\":{\"retired\":null,\"objectId\":\"15679...</td>\n",
       "      <td>103247082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>589020360</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:18 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247085\":{\"retired\":null,\"objectId\":\"16514...</td>\n",
       "      <td>103247085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>589020372</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:21 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247083\":{\"retired\":null,\"objectId\":\"16509...</td>\n",
       "      <td>103247083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>589020385</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:23 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247086\":{\"retired\":null,\"objectId\":\"16515...</td>\n",
       "      <td>103247086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>589020390</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:25 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247082\":{\"retired\":null,\"objectId\":\"15679...</td>\n",
       "      <td>103247082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification_id      user_name  user_id               user_ip  \\\n",
       "0          589019044  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "1          589019067  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "2          589019090  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "3          589019097  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "4          589019337  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "..               ...            ...      ...                   ...   \n",
       "71         589020345  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "72         589020360  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "73         589020372  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "74         589020385  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "75         589020390  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "\n",
       "   workflow_id           workflow_name workflow_version  \\\n",
       "0        27509  Classify with metadata              3.2   \n",
       "1        27509  Classify with metadata              3.2   \n",
       "2        27509  Classify with metadata              3.2   \n",
       "3        27509  Classify with metadata              3.2   \n",
       "4        27509  Classify with metadata              5.6   \n",
       "..         ...                     ...              ...   \n",
       "71       27509  Classify with metadata              5.6   \n",
       "72       27509  Classify with metadata              5.6   \n",
       "73       27509  Classify with metadata              5.6   \n",
       "74       27509  Classify with metadata              5.6   \n",
       "75       27509  Classify with metadata              5.6   \n",
       "\n",
       "                 created_at gold_standard expert  \\\n",
       "0   2024-10-07 16:08:01 UTC                        \n",
       "1   2024-10-07 16:08:07 UTC                        \n",
       "2   2024-10-07 16:08:12 UTC                        \n",
       "3   2024-10-07 16:08:14 UTC                        \n",
       "4   2024-10-07 16:09:17 UTC                        \n",
       "..                      ...           ...    ...   \n",
       "71  2024-10-07 16:13:13 UTC                        \n",
       "72  2024-10-07 16:13:18 UTC                        \n",
       "73  2024-10-07 16:13:21 UTC                        \n",
       "74  2024-10-07 16:13:23 UTC                        \n",
       "75  2024-10-07 16:13:25 UTC                        \n",
       "\n",
       "                                             metadata  \\\n",
       "0   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "1   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "2   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "3   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "4   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "..                                                ...   \n",
       "71  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "72  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "73  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "74  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "75  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "\n",
       "                                          annotations  \\\n",
       "0   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "1   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "2   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "3   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "4   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "..                                                ...   \n",
       "71  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "72  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "73  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "74  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "75  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "\n",
       "                                         subject_data subject_ids  \n",
       "0   {\"103247085\":{\"retired\":null,\"objectId\":\"16514...   103247085  \n",
       "1   {\"103247082\":{\"retired\":null,\"objectId\":\"15679...   103247082  \n",
       "2   {\"103247086\":{\"retired\":null,\"objectId\":\"16515...   103247086  \n",
       "3   {\"103247083\":{\"retired\":null,\"objectId\":\"16509...   103247083  \n",
       "4   {\"103247087\":{\"retired\":null,\"objectId\":\"16513...   103247087  \n",
       "..                                                ...         ...  \n",
       "71  {\"103247082\":{\"retired\":null,\"objectId\":\"15679...   103247082  \n",
       "72  {\"103247085\":{\"retired\":null,\"objectId\":\"16514...   103247085  \n",
       "73  {\"103247083\":{\"retired\":null,\"objectId\":\"16509...   103247083  \n",
       "74  {\"103247086\":{\"retired\":null,\"objectId\":\"16515...   103247086  \n",
       "75  {\"103247082\":{\"retired\":null,\"objectId\":\"15679...   103247082  \n",
       "\n",
       "[76 rows x 14 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda67780-9331-4922-8411-383e169fbf84",
   "metadata": {},
   "source": [
    "Select either `objectId` or `diaObjectId`; this should match the ID type of the data that was first sent to Zooniverse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db961c2e-0304-4d9e-8ac1-9e25197a2fc2",
   "metadata": {},
   "source": [
    "## 4. Extract annotations by task and sort by subject ID\n",
    "There could be multiple tasks per item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0e8cd49-3975-4dec-accd-ef853385bc1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:57:08.026053Z",
     "iopub.status.busy": "2024-10-07T17:57:08.025304Z",
     "iopub.status.idle": "2024-10-07T17:57:08.066581Z",
     "shell.execute_reply": "2024-10-07T17:57:08.065427Z",
     "shell.execute_reply.started": "2024-10-07T17:57:08.026025Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.subject_data {\"103247085\":{\"retired\":null,\"objectId\":\"1651448872733547971\"}}\n",
      "str of the subject_id 103247085\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassification_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m extracted_data\n",
      "Cell \u001b[0;32mIn[57], line 56\u001b[0m, in \u001b[0;36mextract_data\u001b[0;34m(classification_data)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow.subject_data\u001b[39m\u001b[38;5;124m'\u001b[39m, row\u001b[38;5;241m.\u001b[39msubject_data)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr of the subject_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39msubject_ids))\n\u001b[0;32m---> 56\u001b[0m objectId \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubject_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubject_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjectId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjectId\u001b[39m\u001b[38;5;124m'\u001b[39m, objectId)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow.subject_data\u001b[39m\u001b[38;5;124m'\u001b[39m, row\u001b[38;5;241m.\u001b[39msubject_data)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "extracted_data = extract_data(classification_data)\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe65b0-dc50-4550-92a6-a2954c897c12",
   "metadata": {},
   "source": [
    "## 5. Aggregate the annotations\n",
    "Sort by unique subject ID and then unique tasks. Find the most recent classification for each user ID, and uses the Zooniverse consensus builder to look through all user classifications and build consensus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd918a8f-434a-4109-a89a-5f635f71b70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:46:57.981838Z",
     "iopub.status.busy": "2024-10-07T17:46:57.981391Z",
     "iopub.status.idle": "2024-10-07T17:46:58.020648Z",
     "shell.execute_reply": "2024-10-07T17:46:58.019807Z",
     "shell.execute_reply.started": "2024-10-07T17:46:57.981809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len subject-ids-unique 5\n",
      "metadata saved 5\n",
      "subject_id\n",
      "103247082    [{\"103247082\":{\"retired\":null,\"objectId\":\"1567...\n",
      "103247083    [{\"103247083\":{\"retired\":null,\"objectId\":\"1650...\n",
      "103247085    [{\"103247085\":{\"retired\":null,\"objectId\":\"1651...\n",
      "103247086    [{\"103247086\":{\"retired\":null,\"objectId\":\"1651...\n",
      "103247087    [{\"103247087\":{\"retired\":null,\"objectId\":\"1651...\n",
      "Name: metadata, dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aggregated_data \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 101\u001b[0m, in \u001b[0;36maggregate_data\u001b[0;34m(extracted_data)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata saved\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(metadata))\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(metadata)\n\u001b[0;32m--> 101\u001b[0m \u001b[43mSTOP\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# set up a temporary list to store reduced data\u001b[39;00m\n\u001b[1;32m    105\u001b[0m aggregated_rows \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "aggregated_data = aggregate_data(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab35094-bae0-4883-91ed-6d0215a17135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T17:37:12.380491Z",
     "iopub.status.busy": "2024-10-07T17:37:12.379814Z",
     "iopub.status.idle": "2024-10-07T17:37:12.389288Z",
     "shell.execute_reply": "2024-10-07T17:37:12.388726Z",
     "shell.execute_reply.started": "2024-10-07T17:37:12.380459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_likely</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>agreement</th>\n",
       "      <th>aggregation_version</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.1.0</td>\n",
       "      <td>103247082</td>\n",
       "      <td>T0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.1.0</td>\n",
       "      <td>103247083</td>\n",
       "      <td>T0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.1.0</td>\n",
       "      <td>103247085</td>\n",
       "      <td>T0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.1.0</td>\n",
       "      <td>103247086</td>\n",
       "      <td>T0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.1.0</td>\n",
       "      <td>103247087</td>\n",
       "      <td>T0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  most_likely  num_votes  agreement aggregation_version subject_id task\n",
       "0          no          1        1.0               4.1.0  103247082   T0\n",
       "1         yes          1        1.0               4.1.0  103247083   T0\n",
       "2          no          1        1.0               4.1.0  103247085   T0\n",
       "3          no          1        1.0               4.1.0  103247086   T0\n",
       "4         yes          1        1.0               4.1.0  103247087   T0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ad7cd-a9d1-4496-8b70-5cbe26986e2c",
   "metadata": {},
   "source": [
    "## 6. Next steps and additional resources\n",
    "You are now done! Congratulations!\n",
    "Next steps could include joining the above table by subject ID with WHAT????\n",
    "Additional resources include the Zooniverse team's resources to run panoptes through python (https://github.com/zooniverse/panoptes-python-client/tree/master), which includes tools to:\n",
    "- update and\n",
    "- ???? to your project on Zooniverse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee8393-2e9c-4d75-99ab-d4c83ad03f16",
   "metadata": {},
   "source": [
    "For examples of how to work with the data exports, see our Data Digging code repository or use our Panoptes Aggregation python package.\n",
    "https://github.com/zooniverse/Data-digging, https://github.com/zooniverse/aggregation-for-caesar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a06a74-c799-4ef1-bb4c-932e78abbf18",
   "metadata": {},
   "source": [
    "This table contains 14 columns with a bunch of different IDs. The `objectId` or `diaObjectId` entry in the metadata column is necessary to link each classification back to the original ID of the data at the point it was first sent to Zooniverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f99dae-b69b-4ac5-a87f-4eaf4757a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from panoptes_client import Subject\n",
    "\n",
    "# Function to retrieve subject metadata based on subject_id\n",
    "def get_subject_metadata(subject_id):\n",
    "    # Find the subject using the Panoptes client\n",
    "    subject = Subject.find(subject_id)\n",
    "    # Return the metadata associated with the subject (what was in the manifest file)\n",
    "    return subject.metadata\n",
    "\n",
    "# Example usage:\n",
    "metadata = get_subject_metadata(aggregated_data['subject_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993307c-3a85-41ab-84e2-39a2433c9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9540c1-ae86-4421-85bd-dbfd7a969219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
