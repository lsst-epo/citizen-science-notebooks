{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b4daaa-6ff8-467c-8a9b-c56d3e4d9f8b",
   "metadata": {},
   "source": [
    "<img align=\"left\" src = https://project.lsst.org/sites/default/files/Rubin-O-Logo_0.png width=250 style=\"padding: 10px\" alt=\"Vera C. Rubin Observatory Logo\"> \n",
    "<h1 style=\"margin-top: 10px\">Retrieve and Aggregate Zooniverse Output</h1>\n",
    "Authors: Becky Nevin, Clare Higgs, and Eric Rosas <br>\n",
    "Contact author: Clare Higgs <br>\n",
    "Last verified to run: 2024-10-07 <br>\n",
    "LSST Science Pipelines version: Weekly 2024_37 <br>\n",
    "Container size: small or medium <br>\n",
    "Targeted learning level: intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16d57a-9af8-4fc9-bf86-8724024516e6",
   "metadata": {},
   "source": [
    "<b>Description:</b> This notebook guides a PI through the process of retrieving classification data from Zooniverse and builds upon Hayley Robert's Aggregation notebook example. <br><br>\n",
    "<b>Skills:</b> Query for Zooniverse classification data via the panoptes client; retrieve and aggregate user classifications and retrieve original objectIds or diaobjectIds.\n",
    "<br><br>\n",
    "<b>LSST Data Products:</b> n/a<br><br>\n",
    "<b>Packages:</b> panoptes_client, panoptes_aggregation, rubin.citsci, utils (citsci plotting and display utilities),  <br><br>\n",
    "<b>Credit:</b> Hayley Roberts' aggregation code https://github.com/astrohayley/SLSN-Aggregation-Example/blob/main/SLSN_batch_aggregation.py<br><br>\n",
    "<b>Get Support: </b>PIs new to DP0 are encouraged to find documentation and resources at <a href=\"https://dp0-2.lsst.io/\">dp0-2.lsst.io</a>. Support for this notebook is available and questions are welcome at cscience@lsst.org."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa844a-2bd3-41e4-9058-f5ce85c3fc54",
   "metadata": {},
   "source": [
    "## 1. Introduction <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "This notebook provides an introduction to how to use the Zooniverse panoptes client and rubin.citsci package to retrieve classifications from Zooniverse and aggregate the results. Data aggregation in this context is collecting classifications across all citizen scientists and summarizing them by subject in terms of classifier majority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3b241-4e92-49cd-9148-c6b180dc11d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T17:44:28.705146Z",
     "iopub.status.busy": "2024-06-20T17:44:28.704785Z",
     "iopub.status.idle": "2024-06-20T17:44:28.708543Z",
     "shell.execute_reply": "2024-06-20T17:44:28.707909Z",
     "shell.execute_reply.started": "2024-06-20T17:44:28.705123Z"
    }
   },
   "source": [
    "### 1.1 Package imports <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cdc872-8bdf-485b-921f-bb9bd5b597dd",
   "metadata": {},
   "source": [
    "#### Install Pipeline Package\n",
    "\n",
    "First, install the Rubin Citizen Science Pipeline package by doing the following:\n",
    "\n",
    "1. Open up a New Launcher tab\n",
    "2. In the \"Other\" section of the New Launcher tab, click \"Terminal\"\n",
    "3. Use `pip` to install the `rubin.citsci` package by entering the following command:\n",
    "```\n",
    "pip install rubin.citsci\n",
    "```\n",
    "Note that this package will soon be installed directly on RSP.\n",
    "\n",
    "If this package is already installed, make sure it is updated:\n",
    "```\n",
    "pip install --u rubin.citsci\n",
    "```\n",
    "\n",
    "4. Confirm the next cell containing `from rubin.citsci import pipeline` works as expected and does not throw an error\n",
    "\n",
    "5. Install panoptes_client:\n",
    "```\n",
    "pip install panoptes_client\n",
    "pip install panoptes_aggregation\n",
    "```\n",
    "\n",
    "6. If the pip install doesn't work for `panoptes_aggregation`:\n",
    "```\n",
    "pip install -U git+git://github.com/zooniverse/aggregation-for-caesar.git\n",
    "```\n",
    "(https://www.zooniverse.org/talk/1322/2415041?comment=3969837&page=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d65d903-8012-43e3-ab19-d94b3f422e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T13:24:44.805828Z",
     "iopub.status.busy": "2024-10-15T13:24:44.805288Z",
     "iopub.status.idle": "2024-10-15T13:24:47.052975Z",
     "shell.execute_reply": "2024-10-15T13:24:47.052409Z",
     "shell.execute_reply.started": "2024-10-15T13:24:44.805805Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Zooniverse tools\n",
    "from panoptes_client import Panoptes, Workflow\n",
    "from panoptes_aggregation.extractors.utilities import annotation_by_task\n",
    "from panoptes_aggregation.extractors import question_extractor\n",
    "from panoptes_aggregation.reducers import question_consensus_reducer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rubin.citsci import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65e56b-028b-425f-b3c3-87233734a9d7",
   "metadata": {},
   "source": [
    "### 1.2 Define functions and parameters <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "Credit for these functions goes to Hayley Roberts at Zooniverse. This includes:\n",
    "- `download_classifications`: A function to download the classifications given a workflow ID in, which returns a dataframe\n",
    "- `extract_data`: A function to extract user annotations by task and sort by when they were classified??? This can be modified for other classification tasks such as drawing, please see the Zooniverse documentation.\n",
    "- `aggregate_data`: A function that groups by task and user, selects the most recent classification from each user, and uses the Zooniverse `question_consesus_reducer` function to determine the consensus for each subject ID amongst all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d951495-9ed7-44ed-bffe-04504679e8bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T13:31:31.523494Z",
     "iopub.status.busy": "2024-10-15T13:31:31.523183Z",
     "iopub.status.idle": "2024-10-15T13:31:31.535632Z",
     "shell.execute_reply": "2024-10-15T13:31:31.535012Z",
     "shell.execute_reply.started": "2024-10-15T13:31:31.523474Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_classifications(WORKFLOW_ID, client):\n",
    "    \"\"\"\n",
    "    Downloads data from Zooniverse\n",
    "\n",
    "    Args:\n",
    "        WORKFLOW_ID (int): Workflow ID of workflow being aggregated\n",
    "        client: Logged in Zooniverse client\n",
    "\n",
    "    Returns:\n",
    "        classification_data (DataFrame): Raw classifications from Zooniverse\n",
    "    \"\"\"\n",
    "    print('beginning function')\n",
    "    workflow = Workflow(WORKFLOW_ID)\n",
    "    # generate the classifications \n",
    "    # if generate=True, it generates a new classification report,\n",
    "    # which can take a long time because they’re queued in the Zooniverse system.\n",
    "    # It’s the same as going to the project builder and clicking the “request new report”.\n",
    "    # If you don't care about new classifications and are okay with downloading\n",
    "    # an older report that you already generated, you can set this flag to False\n",
    "    with client:\n",
    "        classification_export = workflow.get_export('classifications',\n",
    "                                                    generate=False,\n",
    "                                                    wait=False)\n",
    "        # since it's a partial class, call it to get the DictReader object\n",
    "        csv_dictreader_instance = classification_export.csv_dictreader()\n",
    "        classification_rows = [row for row in tqdm(csv_dictreader_instance, file=sys.stdout)]\n",
    "    # convert to pandas dataframe\n",
    "    classification_data = pd.DataFrame.from_dict(classification_rows)\n",
    "    return classification_data\n",
    "\n",
    "\n",
    "\n",
    "def extract_data(classification_data, id_type='objectId'):\n",
    "    \"\"\"\n",
    "    Extracts annotations from the classification data\n",
    "\n",
    "    Args:\n",
    "        classification_data (DataFrame): Raw classifications from Zooniverse\n",
    "\n",
    "    Returns:\n",
    "        extracted_data (DataFrame): Extracted annotations from raw classification data\n",
    "    \"\"\"\n",
    "    # set up our list where we will store the extracted data temporarily\n",
    "    extracted_rows = []\n",
    "    # iterate through our classification data\n",
    "    for i in range(len(classification_data)):\n",
    "        # access the specific row and extract the annotations\n",
    "        row = classification_data.iloc[i]\n",
    "        for annotation in json.loads(row.annotations):\n",
    "            row_annotation = annotation_by_task({'annotations': [annotation]})\n",
    "            extract = question_extractor(row_annotation)\n",
    "            subject_id_str = str(row.subject_ids)\n",
    "            # Check if the subject ID exists and is a dictionary\n",
    "            if subject_id_str in row.subject_data and isinstance(json.loads(row.subject_data)[subject_id_str], dict):\n",
    "                try:\n",
    "                    rubin_id = json.loads(row.subject_data)[str(row.subject_ids)][id_type]\n",
    "                    print(json.loads(row.subject_data))\n",
    "                    STOp\n",
    "                except KeyError:\n",
    "                    print(json.loads(row.subject_data))\n",
    "                    STOP\n",
    "            else:\n",
    "                print(f\"Key '{subject_id_str}' not found in subject_data or it is not a dictionary.\")\n",
    "            # add the extracted annotations to our temporary list along with some other additional data\n",
    "            extracted_rows.append({\n",
    "                'classification_id': row.classification_id,\n",
    "                'subject_id':        row.subject_ids,\n",
    "                'user_name':         row.user_name,\n",
    "                'user_id':           row.user_id,\n",
    "                'created_at':        row.created_at,\n",
    "                'rubin_id':          rubin_id,\n",
    "                'data':              json.dumps(extract),\n",
    "                'task':              annotation['task']\n",
    "            })\n",
    "    # convert the extracted data to a pandas dataframe and sort\n",
    "    extracted_data = pd.DataFrame.from_dict(extracted_rows)\n",
    "    extracted_data.sort_values(['subject_id', 'created_at'], inplace=True)\n",
    "    return extracted_data\n",
    "\n",
    "def last_filter(data):\n",
    "    \"\"\"\n",
    "    Determines the most recently submitted classifications\n",
    "    \"\"\"\n",
    "    last_time = data.created_at.max()\n",
    "    ldx = data.created_at == last_time\n",
    "    return data[ldx]\n",
    "\n",
    "def aggregate_data(extracted_data):\n",
    "    \"\"\"\n",
    "    Aggregates question data from extracted annotations\n",
    "\n",
    "    Args:\n",
    "        extracted_data (DataFrame): Extracted annotations from raw classifications\n",
    "\n",
    "    Returns:\n",
    "        aggregated_data (DataFrame): Aggregated data for the given workflow\n",
    "    \"\"\"\n",
    "    # generate an array of unique subject ids - these are the ones that we will iterate over\n",
    "    subject_ids_unique = np.unique(extracted_data.subject_id)\n",
    "\n",
    "    # Create a dictionary to map subject IDs to their corresponding metadata\n",
    "    rubin_ids_unique = extracted_data.groupby('subject_id')['rubin_id'].unique()\n",
    "\n",
    "    '''\n",
    "    print('len subject-ids-unique', len(subject_ids_unique))\n",
    "    print('metadata saved', len(rubin_id))\n",
    "    print(rubin_id)\n",
    "    STOP\n",
    "    '''\n",
    "    \n",
    "\n",
    "    # set up a temporary list to store reduced data\n",
    "    aggregated_rows = []\n",
    "\n",
    "    # determine the total number of tasks\n",
    "    tasks = np.unique(extracted_data.task)\n",
    "\n",
    "    # iterating over each unique subject id\n",
    "    for i in range(len(subject_ids_unique)):\n",
    "\n",
    "        # determine the subject_id to work on\n",
    "        subject_id = subject_ids_unique[i]\n",
    "        rubin_id = rubin_ids_unique.iloc[i][0]\n",
    "\n",
    "        # filter the extract_data dataframe for only the subject_id that is being worked on\n",
    "        extract_data_subject = extracted_data[extracted_data.subject_id==subject_id].drop_duplicates()\n",
    "\n",
    "        for task in tasks:\n",
    "\n",
    "            extract_data_filtered = extract_data_subject[extract_data_subject.task == task]\n",
    "\n",
    "            # if there are less unique user submissions than classifications, filter for the most recently updated classification\n",
    "            if (len(extract_data_filtered.user_name.unique()) < len(extract_data_filtered)):\n",
    "                extract_data_filtered = extract_data_filtered.groupby(['user_name'], group_keys=False).apply(last_filter)\n",
    "\n",
    "            # iterate through the filtered extract data to prepare for the reducer\n",
    "            classifications_to_reduce = [json.loads(extract_data_filtered.iloc[j].data) for j in range(len(extract_data_filtered))]\n",
    "\n",
    "            # use the Zooniverse question_consesus_reducer to get the final consensus\n",
    "            # WHAT ARE THE ARGUMENTS THAT ARE OPTIONAL HERE?\n",
    "            reduction = question_consensus_reducer(classifications_to_reduce)\n",
    "\n",
    "            # add the subject id to our reduction data\n",
    "            reduction['subject_id'] = subject_id\n",
    "            reduction['task'] = task\n",
    "            reduction['rubin_id'] = rubin_id\n",
    "\n",
    "            # add the data to our temporary list\n",
    "            aggregated_rows.append(reduction)\n",
    "\n",
    "\n",
    "    # converting the result to a dataframe\n",
    "    aggregated_data = pd.DataFrame.from_dict(aggregated_rows)\n",
    "\n",
    "    # drop rows that are nan\n",
    "    aggregated_data.dropna(inplace=True)\n",
    "\n",
    "    return aggregated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a708c0-046f-4634-a22f-a80dd9b613f2",
   "metadata": {},
   "source": [
    "## 2. Log into Zooniverse and find the workflow to download classifications from\n",
    "If you're running this notebook, you should already have a Zooniverse account with a project with classifications. If you do not yet have an account, please return to notebook `01_Introduction_to_Citsci_Pipeline.ipynb`.\n",
    "\n",
    "IMPORTANT: Your Zooniverse project must be set to \"public\", a \"private\" project will not work. Select this setting under the \"Visibility\" tab, (it does not need to be set to live). \n",
    "\n",
    "Supply the email associated with your Zooniverse account, and then follow the instructions in the prompt to log in and select your project by slug name. \n",
    "\n",
    "A \"slug\" is the string of your Zooniverse username and your project name without the leading forward slash, for instance: \"username/project-name\". [Click here for more details](https://www.zooniverse.org/talk/18/967061?comment=1898157&page=1).\n",
    "\n",
    "**The `rubin.citsci` package includes a method that creates a Zooniverse project from template. If you wish to use this feature, do not provide a slug_name and run the subsequent cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be9aa4e-4ac6-473c-9660-29afbfa9dc74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T13:24:55.233693Z",
     "iopub.status.busy": "2024-10-15T13:24:55.233025Z",
     "iopub.status.idle": "2024-10-15T13:25:04.465396Z",
     "shell.execute_reply": "2024-10-15T13:25:04.464652Z",
     "shell.execute_reply.started": "2024-10-15T13:24:55.233672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and running utilities to establish a link with Zooniverse\n",
      "Enter your Zooniverse username followed by password below\n",
      "Enter your Zooniverse credentials...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Username:  rebecca.nevin\n",
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You now are logged in to the Zooniverse platform.\n",
      "\n",
      "*==* Your Project Slugs *==*\n",
      "\n",
      "rebecca-dot-nevin/template-test-copy-2024-07-09-21-49-53\n",
      "rebecca-dot-nevin/template-test-copy-2024-07-09-19-02-02\n",
      "rebecca-dot-nevin/template-test-copy-2024-07-09-18-53-39\n",
      "rebecca-dot-nevin/template-test-copy-2024-07-03-21-54-30\n",
      "rebecca-dot-nevin/template-test-copy-2024-07-02-22-11-52\n",
      "rebecca-dot-nevin/pcw-2023-awesome-citsci-project\n",
      "rebecca-dot-nevin/test-project\n",
      "rebecca-dot-nevin/galaxy-rotation-fields\n",
      "\n",
      "*==========================*\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which project would you like to connect to? (copy & paste the slug name here)? rebecca-dot-nevin/test-project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project set to: rebecca-dot-nevin/test-project\n"
     ]
    }
   ],
   "source": [
    "email = \"beckynevin@gmail.com\"\n",
    "cit_sci_pipeline = pipeline.CitSciPipeline()\n",
    "cit_sci_pipeline.login_to_zooniverse(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3426882-9f5c-4f8e-bdfb-1daed5230721",
   "metadata": {},
   "source": [
    "Use the `list_workflows` method to find the workflow ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f5808b1-109f-4417-8dd5-003d7d6f83f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T13:25:06.469917Z",
     "iopub.status.busy": "2024-10-15T13:25:06.469602Z",
     "iopub.status.idle": "2024-10-15T13:25:06.775533Z",
     "shell.execute_reply": "2024-10-15T13:25:06.774823Z",
     "shell.execute_reply.started": "2024-10-15T13:25:06.469896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*==* Your Workflows *==*\n",
      "\n",
      "Workflow ID: 27546 - Display Name: Classify with hidden metadata\n",
      "Workflow ID: 27509 - Display Name: Classify with metadata\n",
      "Workflow ID: 23254 - Display Name: Classification\n",
      "\n",
      "*==========================*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cit_sci_pipeline.list_workflows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2d1d1-de4d-414b-afb9-e5b3f6957b68",
   "metadata": {},
   "source": [
    "Copy and paste the above ID into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "505d46f9-c80f-421c-b8d8-92e3093b4d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T13:31:02.285933Z",
     "iopub.status.busy": "2024-10-15T13:31:02.285282Z",
     "iopub.status.idle": "2024-10-15T13:31:02.289367Z",
     "shell.execute_reply": "2024-10-15T13:31:02.288758Z",
     "shell.execute_reply.started": "2024-10-15T13:31:02.285905Z"
    }
   },
   "outputs": [],
   "source": [
    "WORKFLOW_ID = 27509"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234ff23f-b321-4277-a28e-6a2f33e28b1a",
   "metadata": {},
   "source": [
    "## 3. Download the classifications\n",
    "These will still be in the raw format. This function reads from the output csv and puts all rows into a dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e0291a-d5e7-4fca-88d0-6930d32f2d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T13:31:05.218545Z",
     "iopub.status.busy": "2024-10-15T13:31:05.217647Z",
     "iopub.status.idle": "2024-10-15T13:31:05.680071Z",
     "shell.execute_reply": "2024-10-15T13:31:05.679549Z",
     "shell.execute_reply.started": "2024-10-15T13:31:05.218521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning function\n",
      "76it [00:00, 34231.86it/s]\n"
     ]
    }
   ],
   "source": [
    "client = cit_sci_pipeline.client\n",
    "# how long should this take?\n",
    "classification_data = download_classifications(WORKFLOW_ID, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87efe634-b609-483f-b3d3-49f7623fc565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T13:31:06.238586Z",
     "iopub.status.busy": "2024-10-15T13:31:06.238280Z",
     "iopub.status.idle": "2024-10-15T13:31:06.252524Z",
     "shell.execute_reply": "2024-10-15T13:31:06.251986Z",
     "shell.execute_reply.started": "2024-10-15T13:31:06.238565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>workflow_id</th>\n",
       "      <th>workflow_name</th>\n",
       "      <th>workflow_version</th>\n",
       "      <th>created_at</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>expert</th>\n",
       "      <th>metadata</th>\n",
       "      <th>annotations</th>\n",
       "      <th>subject_data</th>\n",
       "      <th>subject_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589019044</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024-10-07 16:08:01 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247085\":{\"retired\":null,\"objectId\":\"16514...</td>\n",
       "      <td>103247085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589019067</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024-10-07 16:08:07 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247082\":{\"retired\":null,\"objectId\":\"15679...</td>\n",
       "      <td>103247082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589019090</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024-10-07 16:08:12 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247086\":{\"retired\":null,\"objectId\":\"16515...</td>\n",
       "      <td>103247086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>589019097</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2024-10-07 16:08:14 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247083\":{\"retired\":null,\"objectId\":\"16509...</td>\n",
       "      <td>103247083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>589019337</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>cee5ed56424764950d55</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:09:17 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247087\":{\"retired\":null,\"objectId\":\"16513...</td>\n",
       "      <td>103247087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>589020345</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:13 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247082\":{\"retired\":null,\"objectId\":\"15679...</td>\n",
       "      <td>103247082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>589020360</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:18 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247085\":{\"retired\":null,\"objectId\":\"16514...</td>\n",
       "      <td>103247085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>589020372</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:21 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247083\":{\"retired\":null,\"objectId\":\"16509...</td>\n",
       "      <td>103247083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>589020385</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:23 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247086\":{\"retired\":null,\"objectId\":\"16515...</td>\n",
       "      <td>103247086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>589020390</td>\n",
       "      <td>rebecca.nevin</td>\n",
       "      <td>1946584</td>\n",
       "      <td>77dde073c5ec44c24799</td>\n",
       "      <td>27509</td>\n",
       "      <td>Classify with metadata</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2024-10-07 16:13:25 UTC</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"60d31e3b15da057584e...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...</td>\n",
       "      <td>{\"103247082\":{\"retired\":null,\"objectId\":\"15679...</td>\n",
       "      <td>103247082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification_id      user_name  user_id               user_ip  \\\n",
       "0          589019044  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "1          589019067  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "2          589019090  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "3          589019097  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "4          589019337  rebecca.nevin  1946584  cee5ed56424764950d55   \n",
       "..               ...            ...      ...                   ...   \n",
       "71         589020345  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "72         589020360  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "73         589020372  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "74         589020385  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "75         589020390  rebecca.nevin  1946584  77dde073c5ec44c24799   \n",
       "\n",
       "   workflow_id           workflow_name workflow_version  \\\n",
       "0        27509  Classify with metadata              3.2   \n",
       "1        27509  Classify with metadata              3.2   \n",
       "2        27509  Classify with metadata              3.2   \n",
       "3        27509  Classify with metadata              3.2   \n",
       "4        27509  Classify with metadata              5.6   \n",
       "..         ...                     ...              ...   \n",
       "71       27509  Classify with metadata              5.6   \n",
       "72       27509  Classify with metadata              5.6   \n",
       "73       27509  Classify with metadata              5.6   \n",
       "74       27509  Classify with metadata              5.6   \n",
       "75       27509  Classify with metadata              5.6   \n",
       "\n",
       "                 created_at gold_standard expert  \\\n",
       "0   2024-10-07 16:08:01 UTC                        \n",
       "1   2024-10-07 16:08:07 UTC                        \n",
       "2   2024-10-07 16:08:12 UTC                        \n",
       "3   2024-10-07 16:08:14 UTC                        \n",
       "4   2024-10-07 16:09:17 UTC                        \n",
       "..                      ...           ...    ...   \n",
       "71  2024-10-07 16:13:13 UTC                        \n",
       "72  2024-10-07 16:13:18 UTC                        \n",
       "73  2024-10-07 16:13:21 UTC                        \n",
       "74  2024-10-07 16:13:23 UTC                        \n",
       "75  2024-10-07 16:13:25 UTC                        \n",
       "\n",
       "                                             metadata  \\\n",
       "0   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "1   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "2   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "3   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "4   {\"source\":\"api\",\"session\":\"f1580a7bdd196dc45e8...   \n",
       "..                                                ...   \n",
       "71  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "72  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "73  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "74  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "75  {\"source\":\"api\",\"session\":\"60d31e3b15da057584e...   \n",
       "\n",
       "                                          annotations  \\\n",
       "0   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "1   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "2   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "3   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "4   [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "..                                                ...   \n",
       "71  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "72  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "73  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "74  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "75  [{\"task\":\"T0\",\"task_label\":\"Is there a galaxy ...   \n",
       "\n",
       "                                         subject_data subject_ids  \n",
       "0   {\"103247085\":{\"retired\":null,\"objectId\":\"16514...   103247085  \n",
       "1   {\"103247082\":{\"retired\":null,\"objectId\":\"15679...   103247082  \n",
       "2   {\"103247086\":{\"retired\":null,\"objectId\":\"16515...   103247086  \n",
       "3   {\"103247083\":{\"retired\":null,\"objectId\":\"16509...   103247083  \n",
       "4   {\"103247087\":{\"retired\":null,\"objectId\":\"16513...   103247087  \n",
       "..                                                ...         ...  \n",
       "71  {\"103247082\":{\"retired\":null,\"objectId\":\"15679...   103247082  \n",
       "72  {\"103247085\":{\"retired\":null,\"objectId\":\"16514...   103247085  \n",
       "73  {\"103247083\":{\"retired\":null,\"objectId\":\"16509...   103247083  \n",
       "74  {\"103247086\":{\"retired\":null,\"objectId\":\"16515...   103247086  \n",
       "75  {\"103247082\":{\"retired\":null,\"objectId\":\"15679...   103247082  \n",
       "\n",
       "[76 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda67780-9331-4922-8411-383e169fbf84",
   "metadata": {},
   "source": [
    "Select either `objectId` or `diaObjectId`; this should match the ID type of the data that was first sent to Zooniverse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db961c2e-0304-4d9e-8ac1-9e25197a2fc2",
   "metadata": {},
   "source": [
    "## 4. Extract annotations by task and sort by subject ID\n",
    "The `id_type` argument should either be set to 'objectId' (default) or 'diaobjectId'. This function will return all annotations, there are repeated rows for some `subject_id` entries from different users or the same user re-classifying the same subject. This function will also return the Rubin IDs in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0e8cd49-3975-4dec-accd-ef853385bc1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T13:31:36.342169Z",
     "iopub.status.busy": "2024-10-15T13:31:36.341328Z",
     "iopub.status.idle": "2024-10-15T13:31:36.379299Z",
     "shell.execute_reply": "2024-10-15T13:31:36.378658Z",
     "shell.execute_reply.started": "2024-10-15T13:31:36.342136Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'103247085': {'retired': None, 'objectId': '1651448872733547971'}}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'STOp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassification_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobjectId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m extracted_data\n",
      "Cell \u001b[0;32mIn[19], line 58\u001b[0m, in \u001b[0;36mextract_data\u001b[0;34m(classification_data, id_type)\u001b[0m\n\u001b[1;32m     56\u001b[0m     rubin_id \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(row\u001b[38;5;241m.\u001b[39msubject_data)[\u001b[38;5;28mstr\u001b[39m(row\u001b[38;5;241m.\u001b[39msubject_ids)][id_type]\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads(row\u001b[38;5;241m.\u001b[39msubject_data))\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mSTOp\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mloads(row\u001b[38;5;241m.\u001b[39msubject_data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOp' is not defined"
     ]
    }
   ],
   "source": [
    "extracted_data = extract_data(classification_data, id_type='objectId')\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe65b0-dc50-4550-92a6-a2954c897c12",
   "metadata": {},
   "source": [
    "## 5. Aggregate the annotations\n",
    "Sort by unique subject ID and then unique tasks. Find the most recent classification for each user ID, and uses the Zooniverse consensus builder to look through all user classifications and build consensus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd918a8f-434a-4109-a89a-5f635f71b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = aggregate_data(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab35094-bae0-4883-91ed-6d0215a17135",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ad7cd-a9d1-4496-8b70-5cbe26986e2c",
   "metadata": {},
   "source": [
    "## 6. Next steps and additional resources\n",
    "You are now done! Congratulations!\n",
    "Next steps could include joining the above table with other LSST data using the `rubin_id` column, which is either objectId or diaobjectId.\n",
    "\n",
    "Additional resources include the Zooniverse team's resources to run panoptes through python (https://github.com/zooniverse/panoptes-python-client/tree/master), which provides high level access to the Zooniverse API in order to manage projects via python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee8393-2e9c-4d75-99ab-d4c83ad03f16",
   "metadata": {},
   "source": [
    "For examples of how to work with the data exports, see our Data Digging code repository or use our Panoptes Aggregation python package.\n",
    "https://github.com/zooniverse/Data-digging, https://github.com/zooniverse/aggregation-for-caesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9540c1-ae86-4421-85bd-dbfd7a969219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
